{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification with LSTM\n",
    "In this notebook we will use LSTMs to do sentiment classification on the [imdb dataset](http://ai.stanford.edu/~amaas/data/sentiment/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data: <br>\n",
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/aclImdb/README'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru-86.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-78.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/test'),\n",
       " PosixPath('/data2/yinterian/aclImdb/imdbEr.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train'),\n",
       " PosixPath('/data2/yinterian/aclImdb/imdb.vocab')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"/data2/yinterian/aclImdb/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "path.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time run this\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "spacy_tok(path.read_text())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/aclImdb/train/pos/8030_9.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/8819_10.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/6316_8.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/4781_8.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/10085_10.txt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
    "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
    "all_files = pos_files + neg_files\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for path in all_files:\n",
    "    counts.update(spacy_tok(path.read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(counts):\n",
    "    if counts[word] < 5:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33918"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could imprive this function by taking a random sample\n",
    "# when sentences are longer than N=400 words \n",
    "def encode_sentence(path, vocab2index, N=400):\n",
    "    x = spacy_tok(path.read_text())\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    enc[N-l:] = enc1[:l]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           1,   774,   101,  2247,   101,   239,    22,  3051,   106,\n",
       "         455,   834,   123,    52,   940,   131,  1999,   276,  3050,\n",
       "        1040,    94,   416,  4813,    94,  4814,    76,  2336,  1100,\n",
       "          76, 31038,    47,   510,   145,  1661,    22,     1,    33,\n",
       "          25, 18194,   376,   746,   931,    74,  1480,   205,  2770,\n",
       "        3235,    52,     3,   392,  4605,    52, 11851,    29,  2879,\n",
       "          12,   276,    99,    25,  1580,  1190,    62,     8,    67,\n",
       "        6907,  2338,    47,   376,    58,    22,  2247,   376,  8076,\n",
       "       28445,    74,  1108,   793,  1436,   145,   302,    62,  1999,\n",
       "        1018,    47,   737,    74,    52,  1131,   847,  5916,    47,\n",
       "        2090,    74,   283,    63,    72,    52,  6027,  4495,     3,\n",
       "       18684,    74,   176,   518, 31038,    64, 14484,  8440,    47,\n",
       "          62,    67,  2748,  4313,    58,     5,    74, 29624,   171,\n",
       "         566,   176,   108,     1,   647,  4771,    72,    67,   166,\n",
       "         185,   145,  2295,    87,    74,  3662,  1342,   101,     5,\n",
       "         101,  1999,  3993,   300,    25,   825,   108, 13693,   392,\n",
       "          84,   277,  2979,    22,  1246,  2548,   836,    33,   442,\n",
       "        3559,  1064,    74, 12230,  1296,    74,   190,   703,   793,\n",
       "        1436,   145,   302,    22,  3051,   106,  3436, 28078,  8855,\n",
       "          47,  2315,    74,    90,    52,   278, 16405,    71,    72,\n",
       "         366,    25,  1580,     3,   116,    18,    52,  1034,   166,\n",
       "        3381,  4813,  4814,    74,   283,  3178,   227,   376,    33,\n",
       "         204,   376,  1839,    47,    84,   227,  7643,    29,   608,\n",
       "         793, 26013,   810,    29,   153,    42,   145,    25,  1818,\n",
       "          72,    52,     3,   354,    94, 31546,   235,    25,   136,\n",
       "        7360,  1580,  4829,    74,   123,  8790,   268,    25,  1580,\n",
       "          47,    54,     1,    22,  6014,  5823,     8,   376,  1370,\n",
       "         131,   271,    13,    22,  1511,  4194,  4829,   376,    25,\n",
       "       14484,  2548,  3760,    76,    22,  1414,   118,  2312,   451,\n",
       "          47,    25, 10699, 18194,  2059,    74,    91,    54,    99,\n",
       "        4813,  4814,   823,   108,   583,     8,    74,    10,    15,\n",
       "          54,   793,   410,   248,   116,  2247,   968,    24,   376,\n",
       "         831,    15,    74,  3662, 26163,    85,    62,   639,    22,\n",
       "       10959,  3449,   566,   271,   108,   442,  1264,  2165,   106,\n",
       "       12225,    24,    62,    74], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "encode_sentence(path, vocab2index, N=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\", N=400):\n",
    "        self.N = N\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        return encode_sentence(path, vocab2index, self.N), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImdbDataset(PATH)\n",
    "test_ds = ImdbDataset(PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  293,  4435,   181,    76,   147,    52,    57,  1734,   132,\n",
       "          238,   137,   523,   463,  7319,    25,  3047,   180,  1879,\n",
       "         2744,  1694,    74,  4420,    52,  1261,    22, 14488, 31950,\n",
       "        16989,    47, 14488,     3,   185,  2019,  1331,    76,  1087,\n",
       "         5949,   250,    74,    90,   283,  6908,  1328, 14488,   123,\n",
       "         3408,     1,     1,    76,     1,   108,  3073,   755,   134,\n",
       "        16794,   131,     3,   577,  3040,    47,   392,  1087,   145,\n",
       "           51,    74,   608,   227,   978,   118,   333,    47,   342,\n",
       "         4439,    79,   140, 15342,    74,   283,   611,   147,    52,\n",
       "         1258,    25,   470,     3, 23727,    47,   777,  3608,    64,\n",
       "           25,   963, 24554,    47,   777,    40,  8328, 11888,   411,\n",
       "           25,   963,    24,   442,   870,  3418,   123,    52,   252,\n",
       "          166,  5810,    25,  2712,   106,   508, 10875,   392,    58,\n",
       "           70,   145,  5928,    25,   120,   131,    74,  3662,   577,\n",
       "          870,     3, 23727,     1,   777,   239,  2605,    76, 14488,\n",
       "           47,     1,   227,  1184,    24,    62,   124,    47,   240,\n",
       "           88,   277,   205,   442,  2561,  1844,  1328,   570,    47,\n",
       "         1470,    35,   392,  1087,    74,     1,  2881,    47,   584,\n",
       "           33,    25,    45,   106,    72,   124,   227,   392,  1572,\n",
       "           47,  1183,    15,    71,    29,    35,  1556,    74, 16376,\n",
       "           76,   106,   245,    76,   469,   342,   390,   145,     1,\n",
       "         4677,   248,   185,  1572,  3358,   106, 23727,    74,   176,\n",
       "           21,   912,    22,  8855,    47, 29300,  1470,    17,    74,\n",
       "          283,   387,   422,   227,    35,  1184,   333,    74,    90,\n",
       "          283,  6908,  1328, 14488,   123,   777,   131,    47,     1,\n",
       "          123,     1,  1607,  5620,    47,    52,   278,   166,  1190,\n",
       "           44,    72,    25,  5950,  1328,   847,     3,   684,   145,\n",
       "           51,    76, 21545,    99,    76,  9564,    47,   106,   245,\n",
       "         2451,    74,   153,     3,   345,   145,   155,   156,   508,\n",
       "         4188,  5889,  2248,  5322,  1136,    76,   342,  2683,   156,\n",
       "          508, 13942,    47,   928, 16128,  1593,   508,  1644,    47,\n",
       "            3,   116,   145,   155,   156, 14488,    47,     1, 22430,\n",
       "         2719,   777,    47,     1,  7937,    76,  7557,    47, 11936,\n",
       "         1342,  8934,    74,   153,  5055,   171, 10639,   145,    25,\n",
       "          872,    47,  1824,    14,   919,    25,    45,   106,    25,\n",
       "          181,    74,    90,     1,  3358,   106,   777,   108,  5947,\n",
       "           47, 14853,  2924,     3,   342,  1607,  2719,    76,   392,\n",
       "           59,   392,    76,    72,    52,  1131,    15,     3,  4391,\n",
       "          145,    51,   338,   777,     3,   392,  1666,    47, 10773,\n",
       "         5986, 23727,   179,    41,   123,   777,   131,  4075,    72,\n",
       "        23727,     3,  3127,    24,    25,   495,   106,   185,  2248,\n",
       "          272,  1644,    87,     1,  3432,     1,    74,  1330,   278,\n",
       "          166,   742,   550,   577,  1314,    76,  2110,    47,  6377,\n",
       "           87,   777,   248, 15869, 23727,    62,   495,    47,    62,\n",
       "           24,  2381,   360,   145], dtype=int32), 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LSTMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
    "# Output dim is the dimension of the hidden layer (4 in this example)\n",
    "lstm = nn.LSTM(2, 4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7282,  0.6077]],\n",
       "\n",
       "        [[-0.3187, -0.7117]],\n",
       "\n",
       "        [[-1.5429,  0.0020]],\n",
       "\n",
       "        [[ 0.0564,  0.0937]],\n",
       "\n",
       "        [[ 1.0420,  1.4207]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 2) for _ in range(5)] # make a sequence of length 5\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNNs assume this input shape\n",
    "# input shape should be seq_len x bash_size x embedding dimension\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMs need two hidden vectors instead of one\n",
    "hidden = (torch.zeros(1, 1, 4), torch.zeros(1, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0284, -0.0016,  0.1897,  0.0487]],\n",
       "\n",
       "        [[-0.0148, -0.0602,  0.1194,  0.1238]],\n",
       "\n",
       "        [[ 0.0118,  0.0869,  0.1618,  0.1522]],\n",
       "\n",
       "        [[-0.0112,  0.0267,  0.2195,  0.1340]],\n",
       "\n",
       "        [[ 0.0082,  0.0329,  0.4125,  0.0744]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0082,  0.0329,  0.4125,  0.0744]]]),\n",
       " tensor([[[ 0.0166,  0.1283,  0.7120,  0.3235]]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embed(x.long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 7, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## x should have dimensions seq_len, batch_size, embedding dimension\n",
    "x = x.transpose(0,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 9\n",
    "lstm = nn.LSTM(embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (torch.zeros(1, batch_size, hidden_dim),\n",
    "     torch.zeros(1, batch_size, hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 7, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 9])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1, h2 = hidden\n",
    "h1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs, hidden) :\n",
    "        x = self.embeddings(inputs)\n",
    "        x = x.transpose(0,1)\n",
    "        lstm_out, lstm_h = self.lstm(x, hidden)\n",
    "        x = lstm_out[-1]\n",
    "        x = self.linearOut(x)\n",
    "        return x, lstm_h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim).cuda(),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            hidden = model.init_hidden(y.shape[0])\n",
    "            y_pred, _ = model(x, hidden)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        print(\"train loss %.3f\" % (sum_loss/total))\n",
    "        test_metrics(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y in test_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().cuda().unsqueeze(1)\n",
    "        hidden = model.init_hidden(y.shape[0])\n",
    "        y_hat, _ = model(x, hidden)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    print(\"test loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImdbDataset(PATH, \"train\", 400)\n",
    "test_ds = ImdbDataset(PATH, \"test\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33920\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMModel(vocab_size, 50, 100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.676\n",
      "test loss 0.661 and accuracy 0.597\n",
      "train loss 0.595\n",
      "test loss 0.578 and accuracy 0.712\n",
      "train loss 0.534\n",
      "test loss 0.545 and accuracy 0.752\n",
      "train loss 0.376\n",
      "test loss 0.462 and accuracy 0.797\n",
      "train loss 0.277\n",
      "test loss 0.434 and accuracy 0.830\n",
      "train loss 0.203\n",
      "test loss 0.480 and accuracy 0.791\n",
      "train loss 0.206\n",
      "test loss 0.499 and accuracy 0.824\n",
      "train loss 0.185\n",
      "test loss 0.569 and accuracy 0.775\n",
      "train loss 0.136\n",
      "test loss 0.536 and accuracy 0.826\n",
      "train loss 0.083\n",
      "test loss 0.617 and accuracy 0.824\n",
      "train loss 0.049\n",
      "test loss 0.642 and accuracy 0.816\n",
      "train loss 0.035\n",
      "test loss 0.730 and accuracy 0.823\n",
      "train loss 0.023\n",
      "test loss 0.770 and accuracy 0.821\n",
      "train loss 0.015\n",
      "test loss 0.823 and accuracy 0.821\n",
      "train loss 0.011\n",
      "test loss 0.861 and accuracy 0.820\n",
      "train loss 0.009\n",
      "test loss 0.932 and accuracy 0.814\n",
      "train loss 0.008\n",
      "test loss 0.947 and accuracy 0.825\n",
      "train loss 0.006\n",
      "test loss 0.991 and accuracy 0.816\n",
      "train loss 0.007\n",
      "test loss 0.980 and accuracy 0.821\n",
      "train loss 0.011\n",
      "test loss 0.939 and accuracy 0.817\n"
     ]
    }
   ],
   "source": [
    "model = train_epocs(model, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-81.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.939 and accuracy 0.817\n"
     ]
    }
   ],
   "source": [
    "test_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs, hidden) :\n",
    "        x = self.embeddings(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x = x.transpose(0,1)\n",
    "        lstm_out, lstm_h = self.gru(x, hidden)\n",
    "        x = lstm_out[-1]\n",
    "        x = self.linearOut(x)\n",
    "        return x, lstm_h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return torch.zeros(1, batch_size, self.hidden_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33920\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model2 = GRUModel(vocab_size, 50, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.676\n",
      "test loss 0.644 and accuracy 0.637\n",
      "train loss 0.595\n",
      "test loss 0.560 and accuracy 0.737\n",
      "train loss 0.455\n",
      "test loss 0.543 and accuracy 0.776\n",
      "train loss 0.380\n",
      "test loss 0.374 and accuracy 0.839\n",
      "train loss 0.274\n",
      "test loss 0.338 and accuracy 0.867\n",
      "train loss 0.199\n",
      "test loss 0.314 and accuracy 0.879\n",
      "train loss 0.264\n",
      "test loss 0.399 and accuracy 0.857\n",
      "train loss 0.151\n",
      "test loss 0.343 and accuracy 0.880\n",
      "train loss 0.111\n",
      "test loss 0.414 and accuracy 0.872\n",
      "train loss 0.087\n",
      "test loss 0.421 and accuracy 0.872\n"
     ]
    }
   ],
   "source": [
    "model2 = train_epocs(model2, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-gru-87.pth\"\n",
    "save_model(model2, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Start with pre-trained embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this notebook is adapted from this [pytorch tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
