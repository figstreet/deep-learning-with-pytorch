{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will write a matrix factorization model in pytorch to solve a recommendation problem. Then we will write a more general neural model for the same problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. https://grouplens.org/datasets/movielens/. To get the data:\n",
    "\n",
    "`wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/ml-latest-small/links.csv'),\n",
       " PosixPath('../data/ml-latest-small/movies.csv'),\n",
       " PosixPath('../data/ml-latest-small/ratings.csv'),\n",
       " PosixPath('../data/ml-latest-small/README.txt'),\n",
       " PosixPath('../data/ml-latest-small/tags.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PATH = Path(\"/data2/yinterian/ml-latest-small/\")\n",
    "PATH = Path(\"../data/ml-latest-small/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\r",
      "\r\n",
      "1,31,2.5,1260759144\r",
      "\r\n",
      "1,1029,3.0,1260759179\r",
      "\r\n",
      "1,1061,3.0,1260759182\r",
      "\r\n",
      "1,1129,2.0,1260759185\r",
      "\r\n",
      "1,1172,4.0,1260759205\r",
      "\r\n",
      "1,1263,2.0,1260759151\r",
      "\r\n",
      "1,1287,2.0,1260759187\r",
      "\r\n",
      "1,1293,2.0,1260759148\r",
      "\r\n",
      "1,1339,3.5,1260759125\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head ../data/ml-latest-small/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH/\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding data\n",
    "This is similar to what you did for your hw1 in ML-2. We enconde the data to have contiguous ids for users and movies. You can think about this as a categorical encoding of our two categorical variables userId and movieId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and validation before encoding\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a handy function modified from fast.ai\n",
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835356031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835355749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835356016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>546</td>\n",
       "      <td>5774</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1085447076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>546</td>\n",
       "      <td>6153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1199217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>546</td>\n",
       "      <td>3034</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1085447067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>546</td>\n",
       "      <td>7939</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1085447033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>546</td>\n",
       "      <td>1408</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1085447015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79979</th>\n",
       "      <td>546</td>\n",
       "      <td>7940</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1085447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79980</th>\n",
       "      <td>546</td>\n",
       "      <td>7941</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1195924922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>546</td>\n",
       "      <td>5889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1087766725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79982</th>\n",
       "      <td>546</td>\n",
       "      <td>1409</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1252767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79983</th>\n",
       "      <td>546</td>\n",
       "      <td>7683</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1127531112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79984</th>\n",
       "      <td>546</td>\n",
       "      <td>1411</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1165014251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79985</th>\n",
       "      <td>546</td>\n",
       "      <td>3800</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1096586145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79986</th>\n",
       "      <td>546</td>\n",
       "      <td>7942</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1199392325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>546</td>\n",
       "      <td>7943</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1088487737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>546</td>\n",
       "      <td>7944</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1087766669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>546</td>\n",
       "      <td>7945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1268554665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79990</th>\n",
       "      <td>546</td>\n",
       "      <td>7946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1087766662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79991</th>\n",
       "      <td>546</td>\n",
       "      <td>7947</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1119305876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79992</th>\n",
       "      <td>546</td>\n",
       "      <td>7948</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1138494345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>546</td>\n",
       "      <td>372</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1131634969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>546</td>\n",
       "      <td>7949</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1190590946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>546</td>\n",
       "      <td>2041</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1189018966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>546</td>\n",
       "      <td>6427</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1199392319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>546</td>\n",
       "      <td>6888</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1094783748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>546</td>\n",
       "      <td>5907</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1199576393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>546</td>\n",
       "      <td>3102</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1087766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>546</td>\n",
       "      <td>2444</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1434029572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>546</td>\n",
       "      <td>4362</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1136441189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>546</td>\n",
       "      <td>6159</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1199392371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>546</td>\n",
       "      <td>1412</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1432359375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80004 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "0           0        0     2.5  1260759144\n",
       "1           0        1     3.0  1260759179\n",
       "2           0        2     3.0  1260759182\n",
       "3           0        3     2.0  1260759185\n",
       "4           0        4     4.0  1260759205\n",
       "5           0        5     2.0  1260759151\n",
       "6           0        6     2.0  1260759187\n",
       "7           0        7     2.0  1260759148\n",
       "8           0        8     3.5  1260759125\n",
       "9           0        9     2.0  1260759131\n",
       "10          0       10     2.5  1260759135\n",
       "11          0       11     1.0  1260759203\n",
       "12          0       12     4.0  1260759191\n",
       "13          0       13     4.0  1260759139\n",
       "14          0       14     3.0  1260759194\n",
       "15          0       15     2.0  1260759198\n",
       "16          0       16     2.0  1260759108\n",
       "17          0       17     2.5  1260759113\n",
       "18          0       18     1.0  1260759200\n",
       "19          0       19     3.0  1260759117\n",
       "20          1       20     4.0   835355493\n",
       "21          1       21     5.0   835355681\n",
       "22          1       22     5.0   835355604\n",
       "23          1       23     4.0   835355552\n",
       "24          1       24     4.0   835355586\n",
       "25          1       25     3.0   835356031\n",
       "26          1       26     3.0   835355749\n",
       "27          1       27     4.0   835355532\n",
       "28          1       28     3.0   835356016\n",
       "29          1       29     5.0   835355395\n",
       "...       ...      ...     ...         ...\n",
       "79974     546     5774     3.0  1085447076\n",
       "79975     546     6153     3.0  1199217972\n",
       "79976     546     3034     1.5  1085447067\n",
       "79977     546     7939     5.0  1085447033\n",
       "79978     546     1408     5.0  1085447015\n",
       "79979     546     7940     2.5  1085447007\n",
       "79980     546     7941     3.5  1195924922\n",
       "79981     546     5889     4.0  1087766725\n",
       "79982     546     1409     3.5  1252767700\n",
       "79983     546     7683     4.0  1127531112\n",
       "79984     546     1411     3.0  1165014251\n",
       "79985     546     3800     2.5  1096586145\n",
       "79986     546     7942     4.0  1199392325\n",
       "79987     546     7943     2.0  1088487737\n",
       "79988     546     7944     4.0  1087766669\n",
       "79989     546     7945     4.0  1268554665\n",
       "79990     546     7946     3.0  1087766662\n",
       "79991     546     7947     4.0  1119305876\n",
       "79992     546     7948     2.5  1138494345\n",
       "79993     546      372     4.5  1131634969\n",
       "79994     546     7949     2.5  1190590946\n",
       "79995     546     2041     4.0  1189018966\n",
       "79996     546     6427     2.5  1199392319\n",
       "79997     546     6888     4.5  1094783748\n",
       "79998     546     5907     4.5  1199576393\n",
       "79999     546     3102     1.5  1087766595\n",
       "80000     546     2444     4.0  1434029572\n",
       "80001     546     4362     2.5  1136441189\n",
       "80002     546     6159     1.5  1199392371\n",
       "80003     546     1412     3.5  1432359375\n",
       "\n",
       "[80004 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check my new implementation\n",
    "df_t = data.copy().loc[:0.8*len(data), :]\n",
    "df_v = data.copy().loc[0.8*len(data):, :]\n",
    "df_t_e = encode_data(df_t)\n",
    "df_v_e = encode_data(df_v, df_t)\n",
    "df_v_e\n",
    "df_t_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = encode_data(train)\n",
    "df_val = encode_data(val, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4607,  0.4401, -0.2978],\n",
       "        [-0.1626,  0.0059, -1.2982],\n",
       "        [-1.7284,  0.8867,  0.1278],\n",
       "        [-0.8376,  0.5045, -0.6134],\n",
       "        [-0.0422,  2.3787, -0.3094],\n",
       "        [-0.6806,  0.0942, -2.5577],\n",
       "        [-0.9507, -2.3724,  1.5018],\n",
       "        [-0.1955,  2.2122, -0.3637],\n",
       "        [-0.8683,  0.7169, -0.7770],\n",
       "        [-0.2438,  0.9544, -0.0693]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an Embedding module containing 10 users or items embedding size 3\n",
    "# embedding will be initialized at random\n",
    "embed = nn.Embedding(10, 3)\n",
    "embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1626,  0.0059, -1.2982],\n",
       "         [ 0.4607,  0.4401, -0.2978],\n",
       "         [-0.1626,  0.0059, -1.2982],\n",
       "         [-0.0422,  2.3787, -0.3094],\n",
       "         [-0.6806,  0.0942, -2.5577],\n",
       "         [-0.1626,  0.0059, -1.2982]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a list of ids we can \"look up\" the embedding corresponing to each id\n",
    "# can you see that some vectors are the same?\n",
    "a = torch.LongTensor([[1,0,1,4,5,1]])\n",
    "embed(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        # initlializing weights\n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        return (u*v).sum(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835356031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835355749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>835356016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>546</td>\n",
       "      <td>5774</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1085447076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>546</td>\n",
       "      <td>6153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1199217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>546</td>\n",
       "      <td>3034</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1085447067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>546</td>\n",
       "      <td>7939</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1085447033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>546</td>\n",
       "      <td>1408</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1085447015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79979</th>\n",
       "      <td>546</td>\n",
       "      <td>7940</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1085447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79980</th>\n",
       "      <td>546</td>\n",
       "      <td>7941</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1195924922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>546</td>\n",
       "      <td>5889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1087766725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79982</th>\n",
       "      <td>546</td>\n",
       "      <td>1409</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1252767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79983</th>\n",
       "      <td>546</td>\n",
       "      <td>7683</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1127531112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79984</th>\n",
       "      <td>546</td>\n",
       "      <td>1411</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1165014251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79985</th>\n",
       "      <td>546</td>\n",
       "      <td>3800</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1096586145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79986</th>\n",
       "      <td>546</td>\n",
       "      <td>7942</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1199392325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>546</td>\n",
       "      <td>7943</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1088487737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>546</td>\n",
       "      <td>7944</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1087766669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>546</td>\n",
       "      <td>7945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1268554665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79990</th>\n",
       "      <td>546</td>\n",
       "      <td>7946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1087766662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79991</th>\n",
       "      <td>546</td>\n",
       "      <td>7947</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1119305876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79992</th>\n",
       "      <td>546</td>\n",
       "      <td>7948</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1138494345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>546</td>\n",
       "      <td>372</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1131634969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>546</td>\n",
       "      <td>7949</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1190590946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>546</td>\n",
       "      <td>2041</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1189018966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>546</td>\n",
       "      <td>6427</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1199392319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>546</td>\n",
       "      <td>6888</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1094783748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>546</td>\n",
       "      <td>5907</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1199576393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>546</td>\n",
       "      <td>3102</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1087766595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>546</td>\n",
       "      <td>2444</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1434029572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80001</th>\n",
       "      <td>546</td>\n",
       "      <td>4362</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1136441189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80002</th>\n",
       "      <td>546</td>\n",
       "      <td>6159</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1199392371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80003</th>\n",
       "      <td>546</td>\n",
       "      <td>1412</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1432359375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80004 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "0           0        0     2.5  1260759144\n",
       "1           0        1     3.0  1260759179\n",
       "2           0        2     3.0  1260759182\n",
       "3           0        3     2.0  1260759185\n",
       "4           0        4     4.0  1260759205\n",
       "5           0        5     2.0  1260759151\n",
       "6           0        6     2.0  1260759187\n",
       "7           0        7     2.0  1260759148\n",
       "8           0        8     3.5  1260759125\n",
       "9           0        9     2.0  1260759131\n",
       "10          0       10     2.5  1260759135\n",
       "11          0       11     1.0  1260759203\n",
       "12          0       12     4.0  1260759191\n",
       "13          0       13     4.0  1260759139\n",
       "14          0       14     3.0  1260759194\n",
       "15          0       15     2.0  1260759198\n",
       "16          0       16     2.0  1260759108\n",
       "17          0       17     2.5  1260759113\n",
       "18          0       18     1.0  1260759200\n",
       "19          0       19     3.0  1260759117\n",
       "20          1       20     4.0   835355493\n",
       "21          1       21     5.0   835355681\n",
       "22          1       22     5.0   835355604\n",
       "23          1       23     4.0   835355552\n",
       "24          1       24     4.0   835355586\n",
       "25          1       25     3.0   835356031\n",
       "26          1       26     3.0   835355749\n",
       "27          1       27     4.0   835355532\n",
       "28          1       28     3.0   835356016\n",
       "29          1       29     5.0   835355395\n",
       "...       ...      ...     ...         ...\n",
       "79974     546     5774     3.0  1085447076\n",
       "79975     546     6153     3.0  1199217972\n",
       "79976     546     3034     1.5  1085447067\n",
       "79977     546     7939     5.0  1085447033\n",
       "79978     546     1408     5.0  1085447015\n",
       "79979     546     7940     2.5  1085447007\n",
       "79980     546     7941     3.5  1195924922\n",
       "79981     546     5889     4.0  1087766725\n",
       "79982     546     1409     3.5  1252767700\n",
       "79983     546     7683     4.0  1127531112\n",
       "79984     546     1411     3.0  1165014251\n",
       "79985     546     3800     2.5  1096586145\n",
       "79986     546     7942     4.0  1199392325\n",
       "79987     546     7943     2.0  1088487737\n",
       "79988     546     7944     4.0  1087766669\n",
       "79989     546     7945     4.0  1268554665\n",
       "79990     546     7946     3.0  1087766662\n",
       "79991     546     7947     4.0  1119305876\n",
       "79992     546     7948     2.5  1138494345\n",
       "79993     546      372     4.5  1131634969\n",
       "79994     546     7949     2.5  1190590946\n",
       "79995     546     2041     4.0  1189018966\n",
       "79996     546     6427     2.5  1199392319\n",
       "79997     546     6888     4.5  1094783748\n",
       "79998     546     5907     4.5  1199576393\n",
       "79999     546     3102     1.5  1087766595\n",
       "80000     546     2444     4.0  1434029572\n",
       "80001     546     4362     2.5  1136441189\n",
       "80002     546     6159     1.5  1199392371\n",
       "80003     546     1412     3.5  1432359375\n",
       "\n",
       "[80004 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users = 547\n",
    "num_items = len(df_t_e.movieId.unique())\n",
    "emb_size = 3\n",
    "\n",
    "user_emb = nn.Embedding(num_users, emb_size)\n",
    "item_emb = nn.Embedding(num_items, emb_size)\n",
    "users = torch.LongTensor(df_t_e.userId.values)\n",
    "items = torch.LongTensor(df_t_e.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = user_emb(users)\n",
    "V = item_emb(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9982,  0.5643,  0.8779],\n",
       "        [ 1.9982,  0.5643,  0.8779],\n",
       "        [ 1.9982,  0.5643,  0.8779],\n",
       "        ...,\n",
       "        [ 0.3930, -0.7139,  0.9420],\n",
       "        [ 0.3930, -0.7139,  0.9420],\n",
       "        [ 0.3930, -0.7139,  0.9420]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5188e-01,  2.5098e-01,  2.2399e-01],\n",
       "        [-3.0469e+00, -4.1524e-01,  1.4471e+00],\n",
       "        [ 9.2608e-01, -1.7749e-02,  5.6746e-01],\n",
       "        ...,\n",
       "        [ 6.4791e-01, -1.3206e+00, -2.8638e-01],\n",
       "        [-4.9191e-01, -6.3665e-01, -1.8377e+00],\n",
       "        [ 1.1919e-01, -3.0660e-01,  1.1518e+00]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element wise multiplication\n",
    "U*V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2308e-01, -2.0151e+00,  1.4758e+00,  ..., -9.5903e-01,\n",
       "        -2.9663e+00,  9.6438e-01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what we want is a dot product per row\n",
    "(U*V).sum(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 8442\n"
     ]
    }
   ],
   "source": [
    "num_users = len(df_train.userId.unique())\n",
    "num_items = len(df_train.movieId.unique())\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MF(num_users, num_items, emb_size=100)  # if you have a GPU .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(df_train.userId.values)  #.cuda()\n",
    "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
    "        ratings = torch.FloatTensor(df_train.rating.values)  #.cuda()\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item()) # used to be loss.data[0]\n",
    "    test_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79799])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([79799, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is what unsqueeze does\n",
    "ratings = torch.FloatTensor(df_train.rating.values)\n",
    "print(ratings.shape)\n",
    "ratings = ratings.unsqueeze(1) #.cuda()\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(df_val.userId.values) # .cuda()\n",
    "    items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
    "    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"test loss %.3f \" % loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.232620239257812\n",
      "5.12353515625\n",
      "2.366079092025757\n",
      "3.451049566268921\n",
      "0.9083771109580994\n",
      "1.806140661239624\n",
      "2.7457008361816406\n",
      "2.2743043899536133\n",
      "1.1538151502609253\n",
      "0.9226882457733154\n",
      "test loss 1.948 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.704465627670288\n",
      "1.0514826774597168\n",
      "0.7490484118461609\n",
      "0.6938858032226562\n",
      "0.7588717341423035\n",
      "0.8396615982055664\n",
      "0.8823750019073486\n",
      "0.8763357996940613\n",
      "0.8344537019729614\n",
      "0.7775422930717468\n",
      "0.7251110672950745\n",
      "0.6901363134384155\n",
      "0.6766709089279175\n",
      "0.6802999973297119\n",
      "0.6914540529251099\n",
      "test loss 0.894 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001524567604065\n",
      "0.6620396971702576\n",
      "0.6681154370307922\n",
      "0.6450682282447815\n",
      "0.637492835521698\n",
      "0.6444087624549866\n",
      "0.6401302814483643\n",
      "0.624942421913147\n",
      "0.6137296557426453\n",
      "0.6124340891838074\n",
      "0.6131712794303894\n",
      "0.607420802116394\n",
      "0.5959214568138123\n",
      "0.5849270820617676\n",
      "0.5780478119850159\n",
      "test loss 0.822 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return (U*V).sum(1) +  b_u  + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MF_bias(num_users, num_items, emb_size=100) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.232122421264648\n",
      "4.367374420166016\n",
      "3.5029284954071045\n",
      "2.4658331871032715\n",
      "0.7884842157363892\n",
      "1.8176424503326416\n",
      "2.5257182121276855\n",
      "2.1455800533294678\n",
      "1.2787482738494873\n",
      "0.9046235680580139\n",
      "test loss 1.537 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.1, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2809542417526245\n",
      "0.8578965067863464\n",
      "0.6950302720069885\n",
      "0.695842981338501\n",
      "0.7546069622039795\n",
      "0.799615204334259\n",
      "0.8063098192214966\n",
      "0.7802164554595947\n",
      "0.7380183339118958\n",
      "0.6968126893043518\n",
      "test loss 0.826 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.01, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6685947775840759\n",
      "0.6605850458145142\n",
      "0.6538867354393005\n",
      "0.6484557390213013\n",
      "0.6441375017166138\n",
      "0.6407522559165955\n",
      "0.6380965709686279\n",
      "0.6359747648239136\n",
      "0.6342198848724365\n",
      "0.6327106356620789\n",
      "test loss 0.811 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6313657164573669\n",
      "0.629359245300293\n",
      "0.6277955770492554\n",
      "0.6263596415519714\n",
      "0.6249339580535889\n",
      "0.6234814524650574\n",
      "0.622002899646759\n",
      "0.6205369830131531\n",
      "0.6190817952156067\n",
      "0.6176358461380005\n",
      "test loss 0.811 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.001, wd=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these models are susceptible to weight initialization, optimization algorithm and regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
    "# Here we could get better results by keep playing with regularization.\n",
    "    \n",
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(CollabFNet, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.drop2 = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = F.relu(torch.cat([U, V], dim=1))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CollabFNet(num_users, num_items, emb_size=100) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.525218963623047\n",
      "12.997052192687988\n",
      "10.415555953979492\n",
      "7.905101299285889\n",
      "5.584404468536377\n",
      "3.608074188232422\n",
      "2.1496787071228027\n",
      "1.3737196922302246\n",
      "1.3723626136779785\n",
      "1.988907814025879\n",
      "2.7540407180786133\n",
      "3.1817948818206787\n",
      "3.154493570327759\n",
      "2.7792327404022217\n",
      "2.252976894378662\n",
      "1.7543985843658447\n",
      "1.3854148387908936\n",
      "1.181867241859436\n",
      "1.1361830234527588\n",
      "1.1938914060592651\n",
      "test loss 1.298 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=20, lr=0.01, wd=1e-5, unsqueeze=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3106966018676758\n",
      "1.1218172311782837\n",
      "1.2025728225708008\n",
      "1.0749306678771973\n",
      "1.0072535276412964\n",
      "1.030681848526001\n",
      "1.0328874588012695\n",
      "0.9771342277526855\n",
      "0.9197388887405396\n",
      "0.9066900014877319\n",
      "0.9182590842247009\n",
      "0.9045007824897766\n",
      "0.8664149641990662\n",
      "0.83624267578125\n",
      "0.8346632122993469\n",
      "0.8377017974853516\n",
      "0.827072262763977\n",
      "0.8043923377990723\n",
      "0.7875887155532837\n",
      "0.7855656147003174\n",
      "test loss 0.834 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=20, lr=0.01, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866000533103943\n",
      "0.7743768692016602\n",
      "0.7719104290008545\n",
      "0.7727627158164978\n",
      "0.7748465538024902\n",
      "0.7732114195823669\n",
      "0.769763708114624\n",
      "0.7679502964019775\n",
      "0.7653291821479797\n",
      "0.7663291692733765\n",
      "test loss 0.816 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.001, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7628862261772156\n",
      "0.762824535369873\n",
      "0.7636146545410156\n",
      "0.7605041265487671\n",
      "0.7590332627296448\n",
      "0.7604009509086609\n",
      "0.7590035200119019\n",
      "0.7582464814186096\n",
      "0.7596232295036316\n",
      "0.7557948231697083\n",
      "0.7566511631011963\n",
      "0.7551475167274475\n",
      "0.7540274858474731\n",
      "0.7542350888252258\n",
      "0.7531538605690002\n",
      "0.7521809935569763\n",
      "0.7521690726280212\n",
      "0.7507472634315491\n",
      "0.7515261173248291\n",
      "0.7497649788856506\n",
      "test loss 0.807 \n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=20, lr=0.001, wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* use t-sne to visualize embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab\n",
    "* Can you use `tags.csv` and `timestamp` to improve your predictions?\n",
    "* Play with the hyperparameters\n",
    "* Look at fastai version of this network and try his transformation https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb\n",
    "* You may need a dataloader if you data is larger. Can you construct one? Here is an example:\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel.html\n",
    "* Work with the largest dataset http://files.grouplens.org/datasets/movielens/ml-latest.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* This notebook is based on [lesson 5 of Jeremy Howard's Deep Learning Course](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, df):\n",
    "        '''Initialization'''\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        X = np.array(self.df.loc[index, ['userId', 'movieId', 'timestamp']])\n",
    "        y = self.df.loc[index, 'rating']\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00000000e+00, 3.10000000e+01, 1.26075914e+09]), 2.5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.DataLoader(d, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x10ebb5b38>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
